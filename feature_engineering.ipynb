{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pydataset import data\n",
    "import wrangle\n",
    "import prepare\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load the tips dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data ('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Create a column named tip_percentage. This should be the tip amount divided by the total bill.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tip_percentage'] = round((df['tip'] / df['total_bill'])*100 , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Create a column named price_per_person. This should be the total bill divided by the party size.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df ['price_per_person']=  df['total_bill'] / df['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Before using any of the methods discussed in the lesson, which features do you think would be most important for predicting the tip amount? The tip percentage?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_bill and size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Use all the other numeric features to predict tip amount. Use select k best and recursive feature elimination to select the top 2 features. What are they?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split data in train, validate and split\n",
    "train, validate, test = wrangle.split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the target and the features\n",
    "X_train = train.drop(columns = ['tip'])\n",
    "y_train = train['tip']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate.drop(columns = ['tip'])\n",
    "X_test = test.drop(columns = ['tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all numerics columns\n",
    "cols = X_train.select_dtypes(exclude='object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled the columns\n",
    "X_train_scaled , X_validate_scaled , X_test_scaled = prepare.scaled_mimmax(cols, X_train , X_validate, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SelectKBest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses an F Test to compare how well each feature predicts the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k=2)\n",
    "f_selector.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the top 2 features\n",
    "mask = f_selector.get_support()\n",
    "X_train_scaled.columns[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive Feature Elimination (RFE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fits a model and recursively eliminates the worst performing features.\n",
    "\n",
    "- Only works for models that can rank features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "rfe = RFE(estimator=lm, n_features_to_select=2)\n",
    "rfe.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the top 2 features\n",
    "\n",
    "X_train_scaled.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.Series(dict(zip(X_train_scaled.columns, rfe.ranking_))).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "- the top 2 features for SelectKBest are: total_bill', 'size'\n",
    "- the top 2 features for Recursive Feature Elimination (RFE) are: 'total_bill', 'tip_percentage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. Use all the other numeric features to predict tip percentage. Use select k best and recursive feature elimination to select the top 2 features. What are they?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the target and the features\n",
    "X_train = train.drop(columns = ['tip_percentage'])\n",
    "y_train = train['tip_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate.drop(columns = ['tip_percentage'])\n",
    "X_test = test.drop(columns = ['tip_percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.select_dtypes(exclude='object').columns.to_list()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled the columns\n",
    "X_train_scaled , X_validate_scaled , X_test_scaled = prepare.scaled_mimmax(cols, X_train , X_validate, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SelectKBest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k=2)\n",
    "f_selector.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask = f_selector.get_support()\n",
    "X_train_scaled.columns[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive Feature Elimination (RFE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "rfe = RFE(estimator=lm, n_features_to_select=2)\n",
    "rfe.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#let's see the ranks \n",
    "pd.Series(dict(zip(X_train_scaled.columns, rfe.ranking_))).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "\n",
    "the top 2 features for SelectKBest are: ''tip_minmax', 'price_per_person_minmax'\n",
    "the top 2 features for Recursive Feature Elimination (RFE) are: 'total_bill_minmax', 'tip_minmax'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f. Why do you think select k best and recursive feature elimination might give different answers for the top features? Does this change as you change the number of features your are selecting?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k=2)\n",
    "f_selector.fit(X_train_scaled, y_train)\n",
    "mask = f_selector.get_support()\n",
    "X_train_scaled.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "rfe = RFE(estimator=lm, n_features_to_select= 2)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "rfe.support_\n",
    "X_train_scaled.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Write a function named select_kbest that takes in the predictors (X), the target (y), and the number of features to select (k) and returns the names of the top k selected features based on the SelectKBest class. Test your function with the tips dataset. You should see the same results as when you did the process manually.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_kbest  (X_df, y_df, n_features):\n",
    "    '''\n",
    "    Takes in the predictors, the target, and the number of features to select (k) ,\n",
    "    and returns the names of the top k selected features based on the SelectKBest class\n",
    "    \n",
    "    X_df : the predictors\n",
    "    y_df : the target\n",
    "    n_features : he number of features to select (k)\n",
    "    Example\n",
    "    select_kbest(X_train_scaled, y_train, 2)\n",
    "    '''\n",
    "    \n",
    "    f_selector = SelectKBest(score_func=f_regression, k= n_features)\n",
    "    f_selector.fit(X_df, y_df)\n",
    "    mask = f_selector.get_support()\n",
    "    X_df.columns[mask]\n",
    "    top = list(X_df.columns[mask])\n",
    "    \n",
    "    return print(f'The top {n_features} selected feautures based on the SelectKBest class are: {top}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_kbest (X_train_scaled, y_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Write a function named rfe that takes in the predictors, the target, and the number of features to select. It should return the top k features based on the RFE class. Test your function with the tips dataset. You should see the same results as when you did the process manually.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe (X_df, y_df, n_features):\n",
    "    lm = LinearRegression()\n",
    "    rfe = RFE(estimator=lm, n_features_to_select= n_features)\n",
    "    rfe.fit(X_df, y_df)\n",
    "    rfe.support_\n",
    "    top = list(X_df.columns[rfe.support_])\n",
    "    return print(f'The top {n_features} selected feautures based on the the RFE class class are: {top}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe (X_train_scaled, y_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Load the swiss dataset and use all the other features to predict Fertility. Find the top 3 features using both select k best and recursive feature elimination (use the functions you just built to help you out).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_df = data('swiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fertility</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Examination</th>\n",
       "      <th>Education</th>\n",
       "      <th>Catholic</th>\n",
       "      <th>Infant.Mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Courtelary</th>\n",
       "      <td>80.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>9.96</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delemont</th>\n",
       "      <td>83.1</td>\n",
       "      <td>45.1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>84.84</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Franches-Mnt</th>\n",
       "      <td>92.5</td>\n",
       "      <td>39.7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>93.40</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moutier</th>\n",
       "      <td>85.8</td>\n",
       "      <td>36.5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>33.77</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuveville</th>\n",
       "      <td>76.9</td>\n",
       "      <td>43.5</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.16</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fertility  Agriculture  Examination  Education  Catholic  \\\n",
       "Courtelary         80.2         17.0           15         12      9.96   \n",
       "Delemont           83.1         45.1            6          9     84.84   \n",
       "Franches-Mnt       92.5         39.7            5          5     93.40   \n",
       "Moutier            85.8         36.5           12          7     33.77   \n",
       "Neuveville         76.9         43.5           17         15      5.16   \n",
       "\n",
       "              Infant.Mortality  \n",
       "Courtelary                22.2  \n",
       "Delemont                  22.2  \n",
       "Franches-Mnt              20.2  \n",
       "Moutier                   20.3  \n",
       "Neuveville                20.6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swiss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swiss_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -> (25, 6)\n",
      "validate -> (12, 6)\n",
      "test -> (10, 6)\n"
     ]
    }
   ],
   "source": [
    "#split data in train, validate and split\n",
    "train, validate, test = wrangle.split_data(swiss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X, y\n",
    "def split_Xy (train, validate, test, target):\n",
    "    '''\n",
    "    This function takes in three dataframe (train, validate, test) and a target  and splits each of the 3 samples\n",
    "    into a dataframe with independent variables and a series with the dependent, or target variable.\n",
    "    The function returns 3 dataframes and 3 series:\n",
    "    X_train (df) & y_train (series), X_validate & y_validate, X_test & y_test.\n",
    "    '''\n",
    "    \n",
    "    #split train\n",
    "    X_train = train.drop(columns= [target])\n",
    "    y_train= train[target]\n",
    "    #split validate\n",
    "    X_validate = validate.drop(columns= [target])\n",
    "    y_validate= validate[target]\n",
    "    #split validate\n",
    "    X_test = test.drop(columns= [target])\n",
    "    y_test= test[target]\n",
    "    return  X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train -> (25, 5)               y_train->(25,)\n",
      "X_validate -> (12, 5)         y_validate->(12,) \n",
      "X_test -> (10, 5)                  y_test>(10,)\n"
     ]
    }
   ],
   "source": [
    "#split Xy using my function\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = wrangle.split_Xy (train, validate, test, 'Fertility' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agriculture', 'Examination', 'Education', 'Catholic', 'Infant.Mortality']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(X_train.select_dtypes(exclude='object').columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled\n",
    "X_train_scaled_df, validate_scaled_df, test_scaled_df = prepare.scaled_mimmax(columns, X_train, X_validate, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 selected feautures based on the SelectKBest class are: ['Examination', 'Catholic', 'Infant.Mortality']\n"
     ]
    }
   ],
   "source": [
    "#kbest\n",
    "select_kbest(X_train_scaled_df, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 selected feautures based on the the RFE class class are: ['Agriculture', 'Examination', 'Infant.Mortality']\n"
     ]
    }
   ],
   "source": [
    "#rfe\n",
    "rfe(X_train_scaled_df, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
